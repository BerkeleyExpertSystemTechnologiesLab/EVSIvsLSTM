{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVSI rank: xmv_10, xmeas_33, xmv_4, xmeas_25, xmeas_21, xmeas_35\n",
    "sensors = ['xmv_10', 'xmv_11', 'xmeas_19', 'xmeas_21', 'xmv_9', 'xmv_4', 'xmv_5', 'xmeas_17', 'xmeas_18', 'xmeas_9']\n",
    "model_path = 'models/' + '0_' + 'none' + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sampled_train = pd.read_csv(\"dataset/train.csv\")\n",
    "Sampled_test = pd.read_csv(\"dataset/test.csv\")\n",
    "Sampled_cv = pd.read_csv('dataset/cv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some mysterious fault type\n",
    "Sampled_train.drop(Sampled_train[(Sampled_train.faultNumber == 3) | (Sampled_train.faultNumber == 9) | (Sampled_train.faultNumber == 15)].index, inplace = True)\n",
    "Sampled_test.drop(Sampled_test[(Sampled_test.faultNumber == 3) | (Sampled_test.faultNumber == 9) | (Sampled_test.faultNumber == 15)].index, inplace = True)\n",
    "Sampled_cv.drop(Sampled_cv[(Sampled_cv.faultNumber == 3) | (Sampled_cv.faultNumber == 9) | (Sampled_cv.faultNumber == 15)].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the Y value usable in LSTM\n",
    "y_train = to_categorical(Sampled_train['faultNumber'],num_classes=21)\n",
    "y_test = to_categorical(Sampled_test['faultNumber'],num_classes=21)\n",
    "y_cv = to_categorical(Sampled_cv['faultNumber'],num_classes=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unused meta data from x\n",
    "x_train_df = Sampled_train.drop(['faultNumber','simulationRun','sample'],axis=1)\n",
    "x_test_df = Sampled_test.drop(['faultNumber','simulationRun','sample'],axis =1)\n",
    "x_cv_df = Sampled_cv.drop(['faultNumber','simulationRun','sample'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmeas_1</th>\n",
       "      <th>xmeas_2</th>\n",
       "      <th>xmeas_3</th>\n",
       "      <th>xmeas_4</th>\n",
       "      <th>xmeas_5</th>\n",
       "      <th>xmeas_6</th>\n",
       "      <th>xmeas_7</th>\n",
       "      <th>xmeas_8</th>\n",
       "      <th>xmeas_9</th>\n",
       "      <th>xmeas_10</th>\n",
       "      <th>...</th>\n",
       "      <th>xmv_2</th>\n",
       "      <th>xmv_3</th>\n",
       "      <th>xmv_4</th>\n",
       "      <th>xmv_5</th>\n",
       "      <th>xmv_6</th>\n",
       "      <th>xmv_7</th>\n",
       "      <th>xmv_8</th>\n",
       "      <th>xmv_9</th>\n",
       "      <th>xmv_10</th>\n",
       "      <th>xmv_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25171</td>\n",
       "      <td>3672.4</td>\n",
       "      <td>4466.3</td>\n",
       "      <td>9.5122</td>\n",
       "      <td>27.057</td>\n",
       "      <td>42.473</td>\n",
       "      <td>2705.6</td>\n",
       "      <td>74.750</td>\n",
       "      <td>120.41</td>\n",
       "      <td>0.33642</td>\n",
       "      <td>...</td>\n",
       "      <td>54.494</td>\n",
       "      <td>24.527</td>\n",
       "      <td>59.710</td>\n",
       "      <td>22.357</td>\n",
       "      <td>40.149</td>\n",
       "      <td>40.074</td>\n",
       "      <td>47.955</td>\n",
       "      <td>47.300</td>\n",
       "      <td>42.100</td>\n",
       "      <td>15.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25234</td>\n",
       "      <td>3642.2</td>\n",
       "      <td>4568.7</td>\n",
       "      <td>9.4145</td>\n",
       "      <td>26.999</td>\n",
       "      <td>42.586</td>\n",
       "      <td>2705.2</td>\n",
       "      <td>75.126</td>\n",
       "      <td>120.38</td>\n",
       "      <td>0.33801</td>\n",
       "      <td>...</td>\n",
       "      <td>53.269</td>\n",
       "      <td>24.465</td>\n",
       "      <td>60.466</td>\n",
       "      <td>22.413</td>\n",
       "      <td>39.956</td>\n",
       "      <td>36.651</td>\n",
       "      <td>45.038</td>\n",
       "      <td>47.502</td>\n",
       "      <td>40.553</td>\n",
       "      <td>16.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.24840</td>\n",
       "      <td>3643.1</td>\n",
       "      <td>4507.5</td>\n",
       "      <td>9.2901</td>\n",
       "      <td>26.927</td>\n",
       "      <td>42.278</td>\n",
       "      <td>2703.5</td>\n",
       "      <td>74.540</td>\n",
       "      <td>120.38</td>\n",
       "      <td>0.33702</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000</td>\n",
       "      <td>24.860</td>\n",
       "      <td>60.642</td>\n",
       "      <td>22.199</td>\n",
       "      <td>40.074</td>\n",
       "      <td>41.868</td>\n",
       "      <td>44.553</td>\n",
       "      <td>47.479</td>\n",
       "      <td>41.341</td>\n",
       "      <td>20.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25153</td>\n",
       "      <td>3628.3</td>\n",
       "      <td>4519.3</td>\n",
       "      <td>9.3347</td>\n",
       "      <td>26.999</td>\n",
       "      <td>42.330</td>\n",
       "      <td>2703.9</td>\n",
       "      <td>74.861</td>\n",
       "      <td>120.38</td>\n",
       "      <td>0.33648</td>\n",
       "      <td>...</td>\n",
       "      <td>53.860</td>\n",
       "      <td>24.553</td>\n",
       "      <td>61.908</td>\n",
       "      <td>21.981</td>\n",
       "      <td>40.141</td>\n",
       "      <td>40.066</td>\n",
       "      <td>48.048</td>\n",
       "      <td>47.440</td>\n",
       "      <td>40.780</td>\n",
       "      <td>17.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.21763</td>\n",
       "      <td>3655.8</td>\n",
       "      <td>4571.0</td>\n",
       "      <td>9.3087</td>\n",
       "      <td>26.901</td>\n",
       "      <td>42.402</td>\n",
       "      <td>2707.7</td>\n",
       "      <td>74.380</td>\n",
       "      <td>120.40</td>\n",
       "      <td>0.32114</td>\n",
       "      <td>...</td>\n",
       "      <td>53.307</td>\n",
       "      <td>21.775</td>\n",
       "      <td>61.891</td>\n",
       "      <td>22.412</td>\n",
       "      <td>37.696</td>\n",
       "      <td>38.295</td>\n",
       "      <td>44.678</td>\n",
       "      <td>47.530</td>\n",
       "      <td>41.089</td>\n",
       "      <td>18.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103995</th>\n",
       "      <td>0.26827</td>\n",
       "      <td>3649.8</td>\n",
       "      <td>4499.3</td>\n",
       "      <td>9.3200</td>\n",
       "      <td>26.802</td>\n",
       "      <td>42.250</td>\n",
       "      <td>2699.1</td>\n",
       "      <td>74.217</td>\n",
       "      <td>120.36</td>\n",
       "      <td>0.33150</td>\n",
       "      <td>...</td>\n",
       "      <td>53.919</td>\n",
       "      <td>26.907</td>\n",
       "      <td>62.637</td>\n",
       "      <td>21.743</td>\n",
       "      <td>40.209</td>\n",
       "      <td>39.039</td>\n",
       "      <td>43.465</td>\n",
       "      <td>49.677</td>\n",
       "      <td>40.592</td>\n",
       "      <td>17.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103996</th>\n",
       "      <td>0.27573</td>\n",
       "      <td>3600.2</td>\n",
       "      <td>4521.3</td>\n",
       "      <td>9.3550</td>\n",
       "      <td>26.812</td>\n",
       "      <td>42.205</td>\n",
       "      <td>2699.8</td>\n",
       "      <td>75.099</td>\n",
       "      <td>120.39</td>\n",
       "      <td>0.35967</td>\n",
       "      <td>...</td>\n",
       "      <td>54.614</td>\n",
       "      <td>26.719</td>\n",
       "      <td>61.912</td>\n",
       "      <td>21.778</td>\n",
       "      <td>42.831</td>\n",
       "      <td>42.310</td>\n",
       "      <td>44.167</td>\n",
       "      <td>49.827</td>\n",
       "      <td>40.957</td>\n",
       "      <td>18.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103997</th>\n",
       "      <td>0.27337</td>\n",
       "      <td>3598.0</td>\n",
       "      <td>4486.2</td>\n",
       "      <td>9.4248</td>\n",
       "      <td>26.464</td>\n",
       "      <td>42.507</td>\n",
       "      <td>2700.2</td>\n",
       "      <td>75.996</td>\n",
       "      <td>120.38</td>\n",
       "      <td>0.35972</td>\n",
       "      <td>...</td>\n",
       "      <td>55.035</td>\n",
       "      <td>26.951</td>\n",
       "      <td>61.747</td>\n",
       "      <td>21.444</td>\n",
       "      <td>42.824</td>\n",
       "      <td>38.587</td>\n",
       "      <td>43.779</td>\n",
       "      <td>49.802</td>\n",
       "      <td>40.755</td>\n",
       "      <td>16.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103998</th>\n",
       "      <td>0.23480</td>\n",
       "      <td>3657.4</td>\n",
       "      <td>4515.7</td>\n",
       "      <td>9.3286</td>\n",
       "      <td>26.779</td>\n",
       "      <td>42.215</td>\n",
       "      <td>2703.6</td>\n",
       "      <td>75.501</td>\n",
       "      <td>120.40</td>\n",
       "      <td>0.34155</td>\n",
       "      <td>...</td>\n",
       "      <td>54.206</td>\n",
       "      <td>23.104</td>\n",
       "      <td>62.557</td>\n",
       "      <td>21.862</td>\n",
       "      <td>40.438</td>\n",
       "      <td>41.286</td>\n",
       "      <td>48.560</td>\n",
       "      <td>49.791</td>\n",
       "      <td>41.916</td>\n",
       "      <td>19.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103999</th>\n",
       "      <td>0.23432</td>\n",
       "      <td>3645.9</td>\n",
       "      <td>4499.5</td>\n",
       "      <td>9.3241</td>\n",
       "      <td>27.066</td>\n",
       "      <td>42.120</td>\n",
       "      <td>2705.8</td>\n",
       "      <td>74.471</td>\n",
       "      <td>120.42</td>\n",
       "      <td>0.34409</td>\n",
       "      <td>...</td>\n",
       "      <td>54.399</td>\n",
       "      <td>23.151</td>\n",
       "      <td>64.714</td>\n",
       "      <td>21.887</td>\n",
       "      <td>40.128</td>\n",
       "      <td>39.617</td>\n",
       "      <td>46.733</td>\n",
       "      <td>49.612</td>\n",
       "      <td>41.477</td>\n",
       "      <td>17.758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89000 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        xmeas_1  xmeas_2  xmeas_3  xmeas_4  xmeas_5  xmeas_6  xmeas_7  \\\n",
       "0       0.25171   3672.4   4466.3   9.5122   27.057   42.473   2705.6   \n",
       "1       0.25234   3642.2   4568.7   9.4145   26.999   42.586   2705.2   \n",
       "2       0.24840   3643.1   4507.5   9.2901   26.927   42.278   2703.5   \n",
       "3       0.25153   3628.3   4519.3   9.3347   26.999   42.330   2703.9   \n",
       "4       0.21763   3655.8   4571.0   9.3087   26.901   42.402   2707.7   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "103995  0.26827   3649.8   4499.3   9.3200   26.802   42.250   2699.1   \n",
       "103996  0.27573   3600.2   4521.3   9.3550   26.812   42.205   2699.8   \n",
       "103997  0.27337   3598.0   4486.2   9.4248   26.464   42.507   2700.2   \n",
       "103998  0.23480   3657.4   4515.7   9.3286   26.779   42.215   2703.6   \n",
       "103999  0.23432   3645.9   4499.5   9.3241   27.066   42.120   2705.8   \n",
       "\n",
       "        xmeas_8  xmeas_9  xmeas_10  ...   xmv_2   xmv_3   xmv_4   xmv_5  \\\n",
       "0        74.750   120.41   0.33642  ...  54.494  24.527  59.710  22.357   \n",
       "1        75.126   120.38   0.33801  ...  53.269  24.465  60.466  22.413   \n",
       "2        74.540   120.38   0.33702  ...  54.000  24.860  60.642  22.199   \n",
       "3        74.861   120.38   0.33648  ...  53.860  24.553  61.908  21.981   \n",
       "4        74.380   120.40   0.32114  ...  53.307  21.775  61.891  22.412   \n",
       "...         ...      ...       ...  ...     ...     ...     ...     ...   \n",
       "103995   74.217   120.36   0.33150  ...  53.919  26.907  62.637  21.743   \n",
       "103996   75.099   120.39   0.35967  ...  54.614  26.719  61.912  21.778   \n",
       "103997   75.996   120.38   0.35972  ...  55.035  26.951  61.747  21.444   \n",
       "103998   75.501   120.40   0.34155  ...  54.206  23.104  62.557  21.862   \n",
       "103999   74.471   120.42   0.34409  ...  54.399  23.151  64.714  21.887   \n",
       "\n",
       "         xmv_6   xmv_7   xmv_8   xmv_9  xmv_10  xmv_11  \n",
       "0       40.149  40.074  47.955  47.300  42.100  15.345  \n",
       "1       39.956  36.651  45.038  47.502  40.553  16.063  \n",
       "2       40.074  41.868  44.553  47.479  41.341  20.452  \n",
       "3       40.141  40.066  48.048  47.440  40.780  17.123  \n",
       "4       37.696  38.295  44.678  47.530  41.089  18.681  \n",
       "...        ...     ...     ...     ...     ...     ...  \n",
       "103995  40.209  39.039  43.465  49.677  40.592  17.575  \n",
       "103996  42.831  42.310  44.167  49.827  40.957  18.122  \n",
       "103997  42.824  38.587  43.779  49.802  40.755  16.289  \n",
       "103998  40.438  41.286  48.560  49.791  41.916  19.503  \n",
       "103999  40.128  39.617  46.733  49.612  41.477  17.758  \n",
       "\n",
       "[89000 rows x 52 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_remover(features_names):\n",
    "    # remove a list of features from x\n",
    "    \n",
    "    dimension = dict()\n",
    "    \n",
    "    # row dimension\n",
    "    dimension['train_row'] = len(x_train_df)\n",
    "    dimension['test_row'] = len(x_test_df)\n",
    "    dimension['cv_row'] = len(x_cv_df)\n",
    "    \n",
    "    # create a copy so we don't change the original dataframe\n",
    "    x_train_masked_df = x_train_df.copy()\n",
    "    x_test_masked_df = x_test_df.copy()\n",
    "    x_cv_masked_df = x_cv_df.copy()\n",
    "    \n",
    "    for feature in features_names:\n",
    "        x_train_masked_df.drop([feature], axis = 1, inplace = True)\n",
    "        x_test_masked_df.drop([feature], axis = 1, inplace = True)\n",
    "        x_cv_masked_df.drop([feature], axis = 1, inplace = True)\n",
    "        \n",
    "    # column dimension\n",
    "    dimension['train_col'] = x_train_masked_df.shape[1]\n",
    "    dimension['test_col'] = x_test_masked_df.shape[1]\n",
    "    dimension['cv_col'] = x_cv_masked_df.shape[1]\n",
    "    \n",
    "    standard_scalar = StandardScaler()\n",
    "    x_train_masked_df = standard_scalar.fit_transform(x_train_masked_df)\n",
    "    x_test_masked_df = standard_scalar.transform(x_test_masked_df)\n",
    "    x_cv_masked_df = standard_scalar.transform(x_cv_masked_df)    \n",
    "    \n",
    "    x_train = np.resize(x_train_masked_df, (dimension['train_row'], dimension['train_col'], 1))\n",
    "    x_test = np.resize(x_test_masked_df, (dimension['test_row'], dimension['test_col'], 1))\n",
    "    x_cv = np.resize(x_cv_masked_df, (dimension['cv_row'], dimension['cv_col'], 1))\n",
    "    \n",
    "    return dimension, x_train, x_test, x_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_cv, y_cv, train_col, feature_name):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256,input_shape= (train_col, 1),return_sequences= True))\n",
    "    model.add(LSTM(128,return_sequences= False))\n",
    "    model.add(Dense(300))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dense(21,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    # training\n",
    "    model.fit(x_train, y_train, epochs=120,verbose=1,batch_size=256,validation_data = (x_cv, y_cv))\n",
    "    \n",
    "    # saving the model\n",
    "    model.save(model_path + feature_name)\n",
    "    \n",
    "    # saving the history\n",
    "    model_paras = model.history\n",
    "    with open(model_path + feature_name + '/history.pickle', 'wb') as handle:\n",
    "        pickle.dump(model_paras.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 48, 256)           264192    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               38700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 21)                2709      \n",
      "=================================================================\n",
      "Total params: 541,249\n",
      "Trainable params: 541,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n",
      "922/922 [==============================] - 15s 16ms/step - loss: 1.7860 - accuracy: 0.4447 - val_loss: 1.3008 - val_accuracy: 0.5990\n",
      "Epoch 2/120\n",
      "922/922 [==============================] - 14s 15ms/step - loss: 1.2675 - accuracy: 0.5885 - val_loss: 1.1609 - val_accuracy: 0.6400\n",
      "Epoch 3/120\n",
      "922/922 [==============================] - 13s 14ms/step - loss: 1.1935 - accuracy: 0.6115 - val_loss: 1.1836 - val_accuracy: 0.6295\n",
      "Epoch 4/120\n",
      "922/922 [==============================] - 13s 15ms/step - loss: 1.1548 - accuracy: 0.6269 - val_loss: 1.1024 - val_accuracy: 0.6645\n",
      "Epoch 5/120\n",
      "922/922 [==============================] - 14s 15ms/step - loss: 1.1093 - accuracy: 0.6441 - val_loss: 1.0996 - val_accuracy: 0.6659\n",
      "Epoch 6/120\n",
      "922/922 [==============================] - 14s 15ms/step - loss: 1.1187 - accuracy: 0.6362 - val_loss: 1.1291 - val_accuracy: 0.6509\n",
      "Epoch 7/120\n",
      "922/922 [==============================] - 14s 15ms/step - loss: 1.0721 - accuracy: 0.6549 - val_loss: 1.1039 - val_accuracy: 0.6613\n",
      "Epoch 8/120\n",
      "922/922 [==============================] - 13s 14ms/step - loss: 1.0598 - accuracy: 0.6575 - val_loss: 1.0810 - val_accuracy: 0.6648\n",
      "Epoch 9/120\n",
      "922/922 [==============================] - 13s 14ms/step - loss: 1.0106 - accuracy: 0.6756 - val_loss: 0.9722 - val_accuracy: 0.7079\n",
      "Epoch 10/120\n",
      "922/922 [==============================] - 13s 14ms/step - loss: 1.0463 - accuracy: 0.6639 - val_loss: 0.9886 - val_accuracy: 0.7007\n",
      "Epoch 11/120\n",
      "922/922 [==============================] - 13s 14ms/step - loss: 0.9824 - accuracy: 0.6862 - val_loss: 1.0830 - val_accuracy: 0.6748\n",
      "Epoch 12/120\n",
      "921/922 [============================>.] - ETA: 0s - loss: 0.9834 - accuracy: 0.6846"
     ]
    }
   ],
   "source": [
    "dimension, x_train, x_test, x_cv = feature_remover(features_names = sensors)\n",
    "print(dimension['train_col'])\n",
    "\n",
    "complete_model = train_model(x_train, y_train, x_cv, y_cv, dimension['train_col'], 'base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sensor in sensors:\n",
    "    remove_sensors = sensors.copy()\n",
    "    remove_sensors.remove(sensor)\n",
    "    dimension, x_train, x_test, x_cv = feature_remover(features_names = remove_sensors)\n",
    "    \n",
    "    print(dimension['train_col'])\n",
    "    \n",
    "    complete_model = train_model(x_train, y_train, x_cv, y_cv, dimension['train_col'], '+' + sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower Branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
